{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 18:31:08,363 - INFO - Logging configurato. File di log salvato in: ../Dataset/output/test1/processing.log\n",
      "2025-01-22 18:31:08,363 - INFO - === Inizio elaborazione del video 'test1.mp4' ===\n",
      "2025-01-22 18:31:08,363 - INFO - Eseguo temporal_smoothing_flow su 'test1.mp4'...\n",
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "2025-01-22 18:31:31,323 - INFO - Temporal smoothing flow completed for 'test1.mp4' in 22.96 seconds. Totale frame elaborati: 125\n",
      "2025-01-22 18:31:31,330 - INFO - temporal_smoothing_flow terminato per 'test1.mp4'.\n",
      "2025-01-22 18:31:31,330 - INFO - Eseguo compress_with_motion su 'test1_overlay.mp4' e 'test1_mask.mp4'...\n",
      "2025-01-22 18:31:31,331 - INFO - Avvio della motion-based compression per: test1_overlay.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# Configura il logging con un file di log e un output a schermo\n",
    "def setup_logging(output_dir):\n",
    "    log_file = os.path.join(output_dir, \"processing.log\")\n",
    "    \n",
    "    # Rimuovi tutti i vecchi handler, se esistono\n",
    "    root_logger = logging.getLogger()\n",
    "    while root_logger.hasHandlers():\n",
    "        root_logger.removeHandler(root_logger.handlers[0])\n",
    "    \n",
    "    # Configura il logging con il flush immediato\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file, mode='w', delay=False),  # Scrive subito\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    logging.info(f\"Logging configurato. File di log salvato in: {log_file}\")\n",
    "\n",
    "# Calcola il flusso ottico tra frame successivi di un video (senza riduzione di risoluzione),\n",
    "def temporal_smoothing_flow(\n",
    "    video_path,\n",
    "    output_dir,\n",
    "    flow_threshold=0.5,\n",
    "    alpha_fraction=0.2,\n",
    "    window_size=30,\n",
    "    morph_kernel=2,\n",
    "    save_name=\"overlay.mp4\",\n",
    "    mask_save_name=\"mask.mp4\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Calcola il flusso ottico tra frame successivi di un video (senza riduzione di risoluzione),\n",
    "    accumula le aree di movimento in una coda (window_size), effettua operazioni morfologiche\n",
    "    di apertura/chiusura e salva:\n",
    "      - Un video 'overlay.mp4' che è la copia del video originale.\n",
    "      - Un video 'mask.mp4' con la maschera di movimento rettangolarizzata.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        logging.error(f\"Impossibile aprire il video in ingresso: {video_path}\")\n",
    "        return\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    overlay_path = os.path.join(output_dir, save_name)\n",
    "    mask_path = os.path.join(output_dir, mask_save_name)\n",
    "\n",
    "    # Impostiamo il codec video: 'mp4v' è un codec solitamente ben supportato.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out_overlay = cv2.VideoWriter(overlay_path, fourcc, fps, (width, height))\n",
    "    out_mask = cv2.VideoWriter(mask_path, fourcc, fps, (width, height), isColor=False)\n",
    "\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        logging.error(\"Impossibile leggere il primo frame del video.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    # Convertiamo il primo frame in scala di grigi alla risoluzione piena\n",
    "    prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    mask_queue = deque(maxlen=window_size)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_kernel, morph_kernel))\n",
    "\n",
    "    frame_count = 0  # Per tracciare a che frame siamo\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calcolo del flusso ottico Farneback su tutta la risoluzione originale\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            prev_gray, gray, None, \n",
    "            0.3,   # pyr_scale\n",
    "            2,     # levels\n",
    "            9,     # winsize\n",
    "            2,     # iterations\n",
    "            5,     # poly_n\n",
    "            1.1,   # poly_sigma\n",
    "            0      # flags\n",
    "        )\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1], angleInDegrees=False)\n",
    "\n",
    "        # Maschera con soglia su mag\n",
    "        mask_current = (mag > flow_threshold).astype(np.uint8) * 255\n",
    "        mask_queue.append(mask_current)\n",
    "\n",
    "        # Somma le maschere nella coda\n",
    "        cumulative_mask = np.sum(np.array(mask_queue), axis=0)\n",
    "\n",
    "        # Soglia in base ad alpha_fraction\n",
    "        mask_smoothed = (cumulative_mask >= (alpha_fraction * len(mask_queue) * 255)).astype(np.uint8) * 255\n",
    "\n",
    "        # Operazioni morfologiche di apertura/chiusura\n",
    "        mask_smoothed = cv2.morphologyEx(mask_smoothed, cv2.MORPH_CLOSE, kernel)\n",
    "        mask_smoothed = cv2.morphologyEx(mask_smoothed, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Retangolarizzazione delle aree di movimento\n",
    "        contours, _ = cv2.findContours(mask_smoothed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        mask_rect = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            x_padded = max(0, x )\n",
    "            y_padded = max(0, y )\n",
    "            w_padded = min(w , width - x_padded)\n",
    "            h_padded = min(h  , height - y_padded)\n",
    "            cv2.rectangle(mask_rect, (x_padded, y_padded),\n",
    "                          (x_padded + w_padded, y_padded + h_padded), 255, -1)\n",
    "\n",
    "        # Scrittura dei frame nei rispettivi video\n",
    "        out_overlay.write(frame)\n",
    "        out_mask.write(mask_rect)\n",
    "\n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "    cap.release()\n",
    "    out_overlay.release()\n",
    "    out_mask.release()\n",
    "    end_time = time.time()\n",
    "    logging.info(\n",
    "        f\"Temporal smoothing flow completed for '{os.path.basename(video_path)}' \"\n",
    "        f\"in {end_time - start_time:.2f} seconds. Totale frame elaborati: {frame_count}\"\n",
    "    )\n",
    "\n",
    "# Comprime un video basandosi sul movimento rilevato dalla maschera\n",
    "def compress_with_motion(input_video, mask_video, output_dir):\n",
    "    \"\"\"\n",
    "    Esegue la compressione basata sul movimento (DCT + quantizzazione) usando OpenCV:\n",
    "    - Sulle aree di movimento (indicate dalla maschera) lascia i frame originali a colori.\n",
    "    - Sulle aree senza movimento, applica una compressione DCT più aggressiva e in più\n",
    "      converte quella zona in bianco e nero (scala di grigi).\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    logging.info(f\"Avvio della motion-based compression per: {os.path.basename(input_video)}\")\n",
    "\n",
    "    cap_input = cv2.VideoCapture(input_video)\n",
    "    cap_mask = cv2.VideoCapture(mask_video)\n",
    "\n",
    "    if not cap_input.isOpened():\n",
    "        logging.error(f\"Impossibile aprire il video originale: {input_video}\")\n",
    "        return\n",
    "    if not cap_mask.isOpened():\n",
    "        logging.error(f\"Impossibile aprire il video maschera: {mask_video}\")\n",
    "        return\n",
    "\n",
    "    fps = cap_input.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap_input.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap_input.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    output_video = os.path.join(output_dir, \"compressed.mp4\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "    # Matrice di quantizzazione (più alto => più compressione)\n",
    "    QTY_aggressive = np.full((8, 8), 100, dtype=np.float32)\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret_in, frame_in = cap_input.read()\n",
    "        ret_mask, frame_mask = cap_mask.read()\n",
    "        if not ret_in or not ret_mask:\n",
    "            break\n",
    "        frame_count += 1\n",
    "\n",
    "        # Convertiamo la maschera in scala di grigi se necessario\n",
    "        if len(frame_mask.shape) == 3:\n",
    "            frame_mask = cv2.cvtColor(frame_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Convertiamo il frame in YCrCb per applicare la DCT solo sul canale di luminanza\n",
    "        frame_ycrcb = cv2.cvtColor(frame_in, cv2.COLOR_BGR2YCrCb)\n",
    "        channels = cv2.split(frame_ycrcb)\n",
    "\n",
    "        # Scorriamo a blocchi 8x8\n",
    "        for i in range(0, frame_mask.shape[0], 8):\n",
    "            for j in range(0, frame_mask.shape[1], 8):\n",
    "                # Se in questa zona non c'è movimento, applichiamo DCT + quantizzazione\n",
    "                # e successivamente convertiamo la zona in B/N.\n",
    "                if frame_mask[i:i+8, j:j+8].mean() == 0:\n",
    "                    for c in range(3):\n",
    "                        block = channels[c][i:i+8, j:j+8]\n",
    "                        if block.shape == (8, 8):\n",
    "                            dct_block = cv2.dct(block.astype(np.float32) - 128)\n",
    "                            quantized_block = np.round(dct_block / QTY_aggressive) * QTY_aggressive\n",
    "                            idct_block = cv2.idct(quantized_block) + 128\n",
    "                            channels[c][i:i+8, j:j+8] = np.clip(idct_block, 0, 255)\n",
    "\n",
    "        # Ricostruiamo il frame compresso in BGR\n",
    "        frame_processed = cv2.merge(channels)\n",
    "        frame_processed = cv2.cvtColor(frame_processed, cv2.COLOR_YCrCb2BGR)\n",
    "\n",
    "        # Convertiamo in B/N solo i blocchi senza movimento\n",
    "        for i in range(0, frame_mask.shape[0], 8):\n",
    "            for j in range(0, frame_mask.shape[1], 8):\n",
    "                if frame_mask[i:i+8, j:j+8].mean() == 0:\n",
    "                    roi = frame_processed[i:i+8, j:j+8]\n",
    "                    gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                    gray_roi_bgr = cv2.cvtColor(gray_roi, cv2.COLOR_GRAY2BGR)\n",
    "                    frame_processed[i:i+8, j:j+8] = gray_roi_bgr\n",
    "\n",
    "        out.write(frame_processed)\n",
    "\n",
    "    cap_input.release()\n",
    "    cap_mask.release()\n",
    "    out.release()\n",
    "    end_time = time.time()\n",
    "    logging.info(\n",
    "        f\"Motion-based compression completed for '{os.path.basename(input_video)}' \"\n",
    "        f\"in {end_time - start_time:.2f} seconds. Totale frame elaborati: {frame_count}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Esegue l'intero flusso:\n",
    "    - Per ogni file .mp4 presente nella cartella di input,\n",
    "      1. Crea una sottocartella di output dedicata (es. output/<nome_file_senza_estensione>)\n",
    "      2. Imposta il logging in quella cartella\n",
    "      3. Esegue:\n",
    "         a) temporal_smoothing_flow --> genera overlay.mp4 e mask.mp4\n",
    "         b) compress_with_motion   --> genera compressed.mp4\n",
    "    \"\"\"\n",
    "    start_time_global = time.time()\n",
    "    input_dir = \"../Dataset/input/\"\n",
    "    output_dir = \"../Dataset/output/\"\n",
    "    \n",
    "    # Trova tutti i file mp4 presenti in input_dir\n",
    "    video_list = [f for f in os.listdir(input_dir) if f.lower().endswith(\".mp4\")]\n",
    "    if not video_list:\n",
    "        print(\"Nessun file mp4 trovato nella cartella di input.\")\n",
    "        return\n",
    "    \n",
    "    # Log di riepilogo\n",
    "    logging.info(\"=== INIZIO ELABORAZIONE DI TUTTI I VIDEO ===\")\n",
    "    logging.info(f\"Video trovati: {video_list}\")\n",
    "\n",
    "    # Processa ciascun video\n",
    "    for input_video in video_list:\n",
    "        video_start_time = time.time()\n",
    "\n",
    "        video_name = os.path.splitext(input_video)[0]\n",
    "        video_output_dir = os.path.join(output_dir, video_name)\n",
    "\n",
    "        # Crea la cartella di output per il singolo video\n",
    "        if not os.path.exists(video_output_dir):\n",
    "            os.makedirs(video_output_dir)\n",
    "\n",
    "        # 1. Setup logging per il singolo video\n",
    "        setup_logging(video_output_dir)\n",
    "        logging.info(f\"=== Inizio elaborazione del video '{input_video}' ===\")\n",
    "\n",
    "        # 2. Calcolo del flusso ottico e generazione overlay + mask\n",
    "        logging.info(f\"Eseguo temporal_smoothing_flow su '{input_video}'...\")\n",
    "        temporal_smoothing_flow(\n",
    "            video_path=os.path.join(input_dir, input_video),\n",
    "            output_dir=video_output_dir,\n",
    "            flow_threshold=0.5,    # Parametri di default (regolabili a piacere)\n",
    "            alpha_fraction=0.2,\n",
    "            window_size=30,\n",
    "            morph_kernel=2,\n",
    "            save_name=f\"{video_name}_overlay.mp4\",\n",
    "            mask_save_name=f\"{video_name}_mask.mp4\"\n",
    "        )\n",
    "        logging.info(f\"temporal_smoothing_flow terminato per '{input_video}'.\")\n",
    "\n",
    "        # 3. Compressione basata sul movimento + conversione in B/N delle zone statiche\n",
    "        logging.info(f\"Eseguo compress_with_motion su '{video_name}_overlay.mp4' e '{video_name}_mask.mp4'...\")\n",
    "        compress_with_motion(\n",
    "            input_video=os.path.join(video_output_dir, f\"{video_name}_overlay.mp4\"),\n",
    "            mask_video=os.path.join(video_output_dir, f\"{video_name}_mask.mp4\"),\n",
    "            output_dir=video_output_dir\n",
    "        )\n",
    "        logging.info(f\"compress_with_motion terminato per '{input_video}'.\")\n",
    "\n",
    "        video_end_time = time.time()\n",
    "        logging.info(\n",
    "            f\"=== Elaborazione video '{video_name}' completata in {video_end_time - video_start_time:.2f} secondi. ===\\n\"\n",
    "        )\n",
    "\n",
    "    end_time_global = time.time()\n",
    "    logging.info(f\"=== Elaborazione di tutti i video completata in {end_time_global - start_time_global:.2f} secondi. ===\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
