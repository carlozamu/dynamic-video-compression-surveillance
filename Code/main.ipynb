{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "\n",
    "def add_transparent_overlay(frame, boxes, color=(0, 0, 255), alpha=0.3):\n",
    "    \"\"\"\n",
    "    Disegna rettangoli rossi trasparenti sulle aree di movimento.\n",
    "    \"\"\"\n",
    "    overlay = frame.copy()\n",
    "    for (x, y, w, h) in boxes:\n",
    "        cv2.rectangle(overlay, (x, y), (x + w, y + h), color, -1)\n",
    "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "\n",
    "def temporal_smoothing_flow(\n",
    "    video_path, \n",
    "    output_dir, \n",
    "    flow_threshold=0.5,       # Soglia di magnitudo per considerare un pixel in movimento\n",
    "    alpha_fraction=0.2,       # Percentuale di frame su N in cui il pixel deve essere acceso\n",
    "    window_size=30,           # N: lunghezza finestra temporale\n",
    "    morph_kernel=3,           # Dimensione kernel morfologico ridotto\n",
    "    save_name=\"flow_smoothing_output.mp4\",\n",
    "    mask_save_name=\"movement_mask.mp4\",  # Nome del video maschera binaria\n",
    "    margin=10,                # Padding in pixel\n",
    "    scale_factor=0.5,         # Riduzione di scala per il calcolo dell'Optical Flow\n",
    "    skip_frames=0             # Numero di frame da saltare (0 = nessuno)\n",
    "):\n",
    "    \"\"\"\n",
    "    Rileva il movimento usando Farneback Optical Flow e produce:\n",
    "      - Un video con overlay (rettangoli rossi) = save_name\n",
    "      - Un video con maschera binaria (0/255) = mask_save_name\n",
    "    \"\"\"\n",
    "     \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # VideoWriter per video con overlay\n",
    "    fourcc_overlay = cv2.VideoWriter_fourcc(*'avc1')\n",
    "    output_path = os.path.join(output_dir, save_name)\n",
    "    out_overlay = cv2.VideoWriter(output_path, fourcc_overlay, fps, (width, height))\n",
    "\n",
    "    # VideoWriter per la maschera binaria (isColor=False)\n",
    "    fourcc_mask = cv2.VideoWriter_fourcc(*'avc1')\n",
    "    mask_output_path = os.path.join(output_dir, mask_save_name)\n",
    "    out_mask = cv2.VideoWriter(mask_output_path, fourcc_mask, fps, (width, height), isColor=False)\n",
    "\n",
    "    ret, first_frame = cap.read()\n",
    "\n",
    "\n",
    "    # Converto il primo frame in scala di grigi e riduco per Optical Flow\n",
    "    prev_gray_full = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_gray = cv2.resize(prev_gray_full, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    # Deque per maschere negli ultimi N frame\n",
    "    mask_queue = deque(maxlen=window_size)\n",
    "    frame_count = 1\n",
    "\n",
    "    # Kernel morfologico\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_kernel, morph_kernel))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "\n",
    "        gray_full = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.resize(gray_full, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "        # Optical Flow\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            prev_gray, gray, None,\n",
    "            0.5,    # Scale\n",
    "            2,      # Levels\n",
    "            9,      # Winsize\n",
    "            2,      # Iterations\n",
    "            5,      # Poly_n\n",
    "            1.2,    # Poly_sigma\n",
    "            0       # Flags\n",
    "        )\n",
    "\n",
    "        # Magnitudo e Angolo\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1], angleInDegrees=False)\n",
    "        mask_current_resized = (mag > flow_threshold).astype(np.uint8) * 255\n",
    "        # Risali alla risoluzione originale\n",
    "        mask_current = cv2.resize(mask_current_resized, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Aggiungi la maschera alla coda\n",
    "        mask_queue.append(mask_current)\n",
    "\n",
    "        # Costruisci la maschera \"media\" con smoothing temporale\n",
    "        if frame_count <= window_size:\n",
    "            cumulative_mask = np.sum(np.array(mask_queue), axis=0)\n",
    "        else:\n",
    "            cumulative_mask = np.sum(np.array(mask_queue), axis=0)\n",
    "\n",
    "        mask_smoothed = (cumulative_mask >= (alpha_fraction * len(mask_queue) * 255)).astype(np.uint8) * 255\n",
    "\n",
    "        # Operazioni morfologiche\n",
    "        mask_smoothed = cv2.morphologyEx(mask_smoothed, cv2.MORPH_CLOSE, kernel)\n",
    "        mask_smoothed = cv2.morphologyEx(mask_smoothed, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Trova contorni e crea bounding box\n",
    "        contours, _ = cv2.findContours(mask_smoothed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        boxes = []\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            x_padded = max(0, x - margin)\n",
    "            y_padded = max(0, y - margin)\n",
    "            w_padded = min(w + 2*margin, width - x_padded)\n",
    "            h_padded = min(h + 2*margin, height - y_padded)\n",
    "\n",
    "            if w_padded > 5 and h_padded > 5:\n",
    "                boxes.append((x_padded, y_padded, w_padded, h_padded))\n",
    "\n",
    "        \n",
    "        # Disegno overlay\n",
    "        if boxes:\n",
    "            add_transparent_overlay(frame, boxes, (0, 0, 255), alpha=0.3)\n",
    "\n",
    "\n",
    "        # Crea la maschera binaria con rettangoli pieni\n",
    "        mask_rect = np.zeros((height, width), dtype=np.uint8)\n",
    "        for (x, y, w, h) in boxes:\n",
    "            cv2.rectangle(mask_rect, (x, y), (x + w, y + h), 255, -1)  # -1 riempie il rettangolo\n",
    "\n",
    "        # Scrivi la maschera binaria\n",
    "        out_mask.write(mask_rect)\n",
    "\n",
    "        # Opzionale: visualizza il frame con overlay\n",
    "        #cv2.imshow(\"Temporal Smoothing Flow\", frame)\n",
    "\n",
    "        # Aggiorna\n",
    "        prev_gray = gray.copy()\n",
    "        frame_count += 1\n",
    "\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    out_overlay.release()\n",
    "    out_mask.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    logging.info(f\"Video overlay salvato in: {output_path}\")\n",
    "    logging.info(f\"Video maschera salvato in: {mask_output_path}\")\n",
    "\n",
    "def main():\n",
    "    video_path = \"../Dataset/input/test2.mp4\"\n",
    "    output_dir = \"../Dataset/output/\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    temporal_smoothing_flow(\n",
    "        video_path=video_path,\n",
    "        output_dir=output_dir,\n",
    "        flow_threshold=0.5,\n",
    "        alpha_fraction=0.2,\n",
    "        window_size=9,\n",
    "        morph_kernel=3,\n",
    "        save_name=\"flow_smoothing_output.mp4\",\n",
    "        mask_save_name=\"movement_mask.mp4\",\n",
    "        margin=20,\n",
    "        scale_factor=0.5,\n",
    "        skip_frames=0\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "from numba import jit\n",
    "\n",
    "def setup_logging(output_dir):\n",
    "    log_file = os.path.join(output_dir, \"compression.log\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),  # Salva log su file\n",
    "            logging.StreamHandler()        # Mostra log su console\n",
    "        ]\n",
    "    )\n",
    "    logging.info(f\"Logging configurato. Log salvati in: {log_file}\")\n",
    "\n",
    "\n",
    "def process_blocks(mask, channels, QTY_aggressive, blockSize):\n",
    "    \"\"\"\n",
    "    Ottimizza la quantizzazione dei blocchi statici con Numba per migliorare la velocit√†.\n",
    "    \"\"\"\n",
    "    for i in range(0, mask.shape[0], blockSize):\n",
    "        for j in range(0, mask.shape[1], blockSize):\n",
    "            if mask[i:i+blockSize, j:j+blockSize].mean() == 0:  # Zona senza movimento\n",
    "                for c in range(3):  # Per ogni canale (Y, Cr, Cb)\n",
    "                    block = channels[c][i:i+blockSize, j:j+blockSize]\n",
    "                    if block.shape == (blockSize, blockSize):  # Evita bordi incompleti\n",
    "                        dct_block = cv2.dct(np.float32(block) - 128)\n",
    "                        quantized_block = np.round(dct_block / QTY_aggressive) * QTY_aggressive\n",
    "                        idct_block = cv2.idct(quantized_block) + 128\n",
    "                        channels[c][i:i+blockSize, j:j+blockSize] = np.clip(idct_block, 0, 255).astype(np.uint8)\n",
    "    return channels\n",
    "\n",
    "def quantize_frame(frame_bgr, mask, blockSize=8, QTY_aggressive=None, scale_factor=0.5):\n",
    "    \"\"\"\n",
    "    Applica la quantizzazione aggressiva alle aree statiche con riduzione della risoluzione.\n",
    "    \"\"\"\n",
    "    if QTY_aggressive is None:\n",
    "        QTY_aggressive = np.full((blockSize, blockSize), 100, dtype=np.float32)\n",
    "\n",
    "    # Converti il frame in YCrCb e separa i canali\n",
    "    frame_ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCR_CB)\n",
    "    channels = cv2.split(frame_ycrcb)\n",
    "\n",
    "    # Ridimensiona la maschera per calcoli pi√π rapidi\n",
    "    small_mask = cv2.resize(mask, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_NEAREST)\n",
    "    small_channels = [cv2.resize(c, (0, 0), fx=scale_factor, fy=scale_factor) for c in channels]\n",
    "\n",
    "    # Processa i blocchi statici sulla risoluzione ridotta\n",
    "    small_channels = process_blocks(small_mask, small_channels, QTY_aggressive, blockSize)\n",
    "\n",
    "    # Ridimensiona i canali elaborati alla risoluzione originale\n",
    "    channels = [cv2.resize(c, (mask.shape[1], mask.shape[0])) for c in small_channels]\n",
    "\n",
    "    # Ricombina i canali e riconverti in BGR\n",
    "    return cv2.cvtColor(cv2.merge(channels), cv2.COLOR_YCR_CB2BGR)\n",
    "\n",
    "def compress_frame_with_motion_mask(frame_bgr, mask, blockSize=8):\n",
    "    \"\"\"\n",
    "    Wrapper per applicare la quantizzazione alle aree statiche.\n",
    "    \"\"\"\n",
    "    return quantize_frame(frame_bgr, mask, blockSize)\n",
    "\n",
    "def compress_with_ffmpeg_and_trim(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Applica una compressione HEVC con ffmpeg e ottimizza riducendo le dimensioni.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Compressione HEVC e ottimizzazione avviata per: {input_path}\")\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", input_path,\n",
    "        \"-c:v\", \"libx265\",  # Codec HEVC per alta compressione\n",
    "        \"-crf\", \"28\",       # Compressione pi√π aggressiva\n",
    "        \"-preset\", \"ultrafast\",  # Ottimizzazione per velocit√†\n",
    "        \"-y\",               # Sovrascrive l'output se esistente\n",
    "        output_path\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(ffmpeg_command, check=True)\n",
    "        logging.info(f\"Compressione completata. Video ottimizzato salvato in: {output_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logging.error(f\"Errore durante la compressione con ffmpeg: {e}\")\n",
    "\n",
    "def main_compress_with_motion(input_video, motionMask_video, output_video=\"COMPRESSION_quantized_static.mp4\"):\n",
    "    \"\"\"\n",
    "    Rimuove informazioni dalle aree statiche applicando quantizzazione e ottimizza la compressione.\n",
    "    \"\"\"\n",
    "    cap_input = cv2.VideoCapture(input_video)\n",
    "    cap_mask = cv2.VideoCapture(motionMask_video)\n",
    "\n",
    "    if not cap_input.isOpened():\n",
    "        logging.error(f\"Impossibile aprire il video originale: {input_video}\")\n",
    "        return\n",
    "    if not cap_mask.isOpened():\n",
    "        logging.error(f\"Impossibile aprire il video maschera: {motionMask_video}\")\n",
    "        return\n",
    "\n",
    "    fps = cap_input.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap_input.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap_input.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # VideoWriter per il video di output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
    "    output_path = os.path.join(os.path.dirname(motionMask_video), output_video)\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret_in, frame_in = cap_input.read()\n",
    "        ret_mask, frame_mask = cap_mask.read()\n",
    "        if not ret_in or not ret_mask:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Verifica dimensioni maschera e frame\n",
    "        if frame_in.shape[:2] != frame_mask.shape[:2]:\n",
    "            logging.error(\"Dimensioni di frame e maschera non corrispondono!\")\n",
    "            break\n",
    "\n",
    "        # Quantizza le aree statiche\n",
    "        processed_frame = compress_frame_with_motion_mask(\n",
    "            frame_in, \n",
    "            frame_mask,\n",
    "            blockSize=16\n",
    "        )\n",
    "\n",
    "        # Scrivi il frame nel video di output\n",
    "        out.write(processed_frame)\n",
    "\n",
    "    cap_input.release()\n",
    "    cap_mask.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Esegui compressione con ffmpeg e ottimizza\n",
    "    optimized_output = output_path.replace(\".mp4\", \"_optimized.mp4\")\n",
    "    compress_with_ffmpeg_and_trim(output_path, optimized_output)\n",
    "\n",
    "def main():\n",
    "    video_originale = \"../Dataset/input/test2.mp4\"\n",
    "    output_dir = \"../Dataset/output/\"\n",
    "    mask_video_path = os.path.join(output_dir, \"movement_mask.mp4\")  # Generato dal Blocco 1\n",
    "    video_compresso = \"COMPRESSION_quantized_static.mp4\"\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    setup_logging(output_dir)\n",
    "\n",
    "    main_compress_with_motion(\n",
    "        input_video=video_originale,\n",
    "        motionMask_video=mask_video_path,\n",
    "        output_video=video_compresso\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
