{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 10:19:36,241 - INFO - Logging configurato. Log salvati in: ../Dataset/output/motion_smoothing.log\n",
      "2025-01-18 10:19:36,242 - INFO - === Inizio Optical Flow con Buffer Temporale ===\n",
      "2025-01-18 10:19:36,243 - INFO - Video input: ../Dataset/input/test2.mp4\n",
      "2025-01-18 10:19:36,243 - INFO - Finestra temporale: N=9, soglia %=0.2, scale_factor=0.5\n",
      "2025-01-18 10:19:36,278 - INFO - FPS: 60.05879882402352 | Dimensioni: 1920x1080\n",
      "2025-01-18 10:19:37,141 - INFO - Frame 10 - 107 aree di movimento\n",
      "2025-01-18 10:19:37,980 - INFO - Frame 20 - 50 aree di movimento\n",
      "2025-01-18 10:19:38,831 - INFO - Frame 30 - 50 aree di movimento\n",
      "2025-01-18 10:19:39,663 - INFO - Frame 40 - 52 aree di movimento\n",
      "2025-01-18 10:19:40,517 - INFO - Frame 50 - 59 aree di movimento\n",
      "2025-01-18 10:19:41,393 - INFO - Frame 60 - 111 aree di movimento\n",
      "2025-01-18 10:19:42,333 - INFO - Frame 70 - 55 aree di movimento\n",
      "2025-01-18 10:19:43,220 - INFO - Frame 80 - 63 aree di movimento\n",
      "2025-01-18 10:19:44,075 - INFO - Frame 90 - 45 aree di movimento\n",
      "2025-01-18 10:19:44,938 - INFO - Frame 100 - 50 aree di movimento\n",
      "2025-01-18 10:19:45,836 - INFO - Frame 110 - 49 aree di movimento\n",
      "2025-01-18 10:19:46,697 - INFO - Frame 120 - 81 aree di movimento\n",
      "2025-01-18 10:19:47,556 - INFO - Frame 130 - 34 aree di movimento\n",
      "2025-01-18 10:19:48,414 - INFO - Frame 140 - 44 aree di movimento\n",
      "2025-01-18 10:19:49,275 - INFO - Frame 150 - 39 aree di movimento\n",
      "2025-01-18 10:19:50,133 - INFO - Frame 160 - 49 aree di movimento\n",
      "2025-01-18 10:19:50,990 - INFO - Frame 170 - 38 aree di movimento\n",
      "2025-01-18 10:19:51,840 - INFO - Frame 180 - 72 aree di movimento\n",
      "2025-01-18 10:19:52,695 - INFO - Frame 190 - 53 aree di movimento\n",
      "2025-01-18 10:19:53,553 - INFO - Frame 200 - 35 aree di movimento\n",
      "2025-01-18 10:19:54,405 - INFO - Frame 210 - 47 aree di movimento\n",
      "2025-01-18 10:19:55,261 - INFO - Frame 220 - 51 aree di movimento\n",
      "2025-01-18 10:19:56,114 - INFO - Frame 230 - 49 aree di movimento\n",
      "2025-01-18 10:19:56,967 - INFO - Frame 240 - 98 aree di movimento\n",
      "2025-01-18 10:19:57,843 - INFO - Frame 250 - 43 aree di movimento\n",
      "2025-01-18 10:19:58,703 - INFO - Frame 260 - 42 aree di movimento\n",
      "2025-01-18 10:19:59,601 - INFO - Frame 270 - 54 aree di movimento\n",
      "2025-01-18 10:20:00,462 - INFO - Frame 280 - 42 aree di movimento\n",
      "2025-01-18 10:20:01,324 - INFO - Frame 290 - 51 aree di movimento\n",
      "2025-01-18 10:20:02,176 - INFO - Frame 300 - 121 aree di movimento\n",
      "2025-01-18 10:20:03,028 - INFO - Frame 310 - 54 aree di movimento\n",
      "2025-01-18 10:20:03,883 - INFO - Frame 320 - 48 aree di movimento\n",
      "2025-01-18 10:20:04,730 - INFO - Frame 330 - 61 aree di movimento\n",
      "2025-01-18 10:20:05,579 - INFO - Frame 340 - 69 aree di movimento\n",
      "2025-01-18 10:20:06,435 - INFO - Frame 350 - 56 aree di movimento\n",
      "2025-01-18 10:20:07,296 - INFO - Frame 360 - 109 aree di movimento\n",
      "2025-01-18 10:20:08,152 - INFO - Frame 370 - 57 aree di movimento\n",
      "2025-01-18 10:20:09,005 - INFO - Frame 380 - 56 aree di movimento\n",
      "2025-01-18 10:20:09,860 - INFO - Frame 390 - 55 aree di movimento\n",
      "2025-01-18 10:20:10,718 - INFO - Frame 400 - 38 aree di movimento\n",
      "2025-01-18 10:20:11,577 - INFO - Frame 410 - 37 aree di movimento\n",
      "2025-01-18 10:20:12,429 - INFO - Frame 420 - 95 aree di movimento\n",
      "2025-01-18 10:20:13,286 - INFO - Frame 430 - 38 aree di movimento\n",
      "2025-01-18 10:20:14,143 - INFO - Frame 440 - 39 aree di movimento\n",
      "2025-01-18 10:20:14,991 - INFO - Frame 450 - 74 aree di movimento\n",
      "2025-01-18 10:20:15,850 - INFO - Frame 460 - 61 aree di movimento\n",
      "2025-01-18 10:20:16,706 - INFO - Frame 470 - 39 aree di movimento\n",
      "2025-01-18 10:20:17,554 - INFO - Frame 480 - 113 aree di movimento\n",
      "2025-01-18 10:20:18,412 - INFO - Frame 490 - 39 aree di movimento\n",
      "2025-01-18 10:20:19,290 - INFO - Frame 500 - 48 aree di movimento\n",
      "2025-01-18 10:20:20,162 - INFO - Frame 510 - 35 aree di movimento\n",
      "2025-01-18 10:20:21,023 - INFO - Frame 520 - 37 aree di movimento\n",
      "2025-01-18 10:20:21,901 - INFO - Frame 530 - 53 aree di movimento\n",
      "2025-01-18 10:20:22,770 - INFO - Frame 540 - 91 aree di movimento\n",
      "2025-01-18 10:20:23,625 - INFO - Frame 550 - 46 aree di movimento\n",
      "2025-01-18 10:20:24,480 - INFO - Frame 560 - 45 aree di movimento\n",
      "2025-01-18 10:20:25,331 - INFO - Frame 570 - 36 aree di movimento\n",
      "2025-01-18 10:20:26,181 - INFO - Frame 580 - 39 aree di movimento\n",
      "2025-01-18 10:20:27,035 - INFO - Frame 590 - 40 aree di movimento\n",
      "2025-01-18 10:20:27,891 - INFO - Frame 600 - 111 aree di movimento\n",
      "2025-01-18 10:20:28,751 - INFO - Frame 610 - 46 aree di movimento\n",
      "2025-01-18 10:20:29,622 - INFO - Frame 620 - 49 aree di movimento\n",
      "2025-01-18 10:20:30,484 - INFO - Frame 630 - 47 aree di movimento\n",
      "2025-01-18 10:20:31,352 - INFO - Frame 640 - 56 aree di movimento\n",
      "2025-01-18 10:20:32,214 - INFO - Frame 650 - 43 aree di movimento\n",
      "2025-01-18 10:20:33,064 - INFO - Frame 660 - 115 aree di movimento\n",
      "2025-01-18 10:20:33,960 - INFO - Frame 670 - 58 aree di movimento\n",
      "2025-01-18 10:20:34,822 - INFO - Frame 680 - 57 aree di movimento\n",
      "2025-01-18 10:20:35,683 - INFO - Frame 690 - 51 aree di movimento\n",
      "2025-01-18 10:20:36,548 - INFO - Frame 700 - 46 aree di movimento\n",
      "2025-01-18 10:20:37,409 - INFO - Frame 710 - 52 aree di movimento\n",
      "2025-01-18 10:20:38,275 - INFO - Frame 720 - 97 aree di movimento\n",
      "2025-01-18 10:20:39,133 - INFO - Frame 730 - 36 aree di movimento\n",
      "2025-01-18 10:20:39,981 - INFO - Frame 740 - 51 aree di movimento\n",
      "2025-01-18 10:20:40,836 - INFO - Frame 750 - 44 aree di movimento\n",
      "2025-01-18 10:20:41,690 - INFO - Frame 760 - 37 aree di movimento\n",
      "2025-01-18 10:20:42,546 - INFO - Frame 770 - 41 aree di movimento\n",
      "2025-01-18 10:20:43,399 - INFO - Frame 780 - 91 aree di movimento\n",
      "2025-01-18 10:20:44,283 - INFO - Frame 790 - 49 aree di movimento\n",
      "2025-01-18 10:20:45,131 - INFO - Frame 800 - 48 aree di movimento\n",
      "2025-01-18 10:20:45,987 - INFO - Frame 810 - 48 aree di movimento\n",
      "2025-01-18 10:20:46,850 - INFO - Frame 820 - 47 aree di movimento\n",
      "2025-01-18 10:20:47,700 - INFO - Frame 830 - 46 aree di movimento\n",
      "2025-01-18 10:20:48,575 - INFO - Frame 840 - 93 aree di movimento\n",
      "2025-01-18 10:20:49,448 - INFO - Frame 850 - 45 aree di movimento\n",
      "2025-01-18 10:20:50,301 - INFO - Frame 860 - 41 aree di movimento\n",
      "2025-01-18 10:20:51,147 - INFO - Frame 870 - 60 aree di movimento\n",
      "2025-01-18 10:20:51,994 - INFO - Frame 880 - 42 aree di movimento\n",
      "2025-01-18 10:20:52,841 - INFO - Frame 890 - 50 aree di movimento\n",
      "2025-01-18 10:20:53,688 - INFO - Frame 900 - 101 aree di movimento\n",
      "2025-01-18 10:20:54,559 - INFO - Frame 910 - 54 aree di movimento\n",
      "2025-01-18 10:20:55,426 - INFO - Frame 920 - 61 aree di movimento\n",
      "2025-01-18 10:20:56,294 - INFO - Frame 930 - 58 aree di movimento\n",
      "2025-01-18 10:20:57,154 - INFO - Frame 940 - 53 aree di movimento\n",
      "2025-01-18 10:20:58,008 - INFO - Frame 950 - 60 aree di movimento\n",
      "2025-01-18 10:20:58,868 - INFO - Frame 960 - 96 aree di movimento\n",
      "2025-01-18 10:20:59,725 - INFO - Frame 970 - 43 aree di movimento\n",
      "2025-01-18 10:21:00,575 - INFO - Frame 980 - 64 aree di movimento\n",
      "2025-01-18 10:21:01,450 - INFO - Frame 990 - 50 aree di movimento\n",
      "2025-01-18 10:21:02,320 - INFO - Frame 1000 - 61 aree di movimento\n",
      "2025-01-18 10:21:03,176 - INFO - Frame 1010 - 55 aree di movimento\n",
      "2025-01-18 10:21:04,037 - INFO - Frame 1020 - 114 aree di movimento\n",
      "2025-01-18 10:21:04,890 - INFO - Frame 1030 - 56 aree di movimento\n",
      "2025-01-18 10:21:05,743 - INFO - Frame 1040 - 51 aree di movimento\n",
      "2025-01-18 10:21:06,586 - INFO - Frame 1050 - 55 aree di movimento\n",
      "2025-01-18 10:21:07,459 - INFO - Frame 1060 - 47 aree di movimento\n",
      "2025-01-18 10:21:08,328 - INFO - Frame 1070 - 53 aree di movimento\n",
      "2025-01-18 10:21:09,183 - INFO - Frame 1080 - 95 aree di movimento\n",
      "2025-01-18 10:21:10,039 - INFO - Frame 1090 - 40 aree di movimento\n",
      "2025-01-18 10:21:10,895 - INFO - Frame 1100 - 51 aree di movimento\n",
      "2025-01-18 10:21:11,750 - INFO - Frame 1110 - 52 aree di movimento\n",
      "2025-01-18 10:21:12,595 - INFO - Frame 1120 - 53 aree di movimento\n",
      "2025-01-18 10:21:13,447 - INFO - Frame 1130 - 41 aree di movimento\n",
      "2025-01-18 10:21:14,296 - INFO - Frame 1140 - 98 aree di movimento\n",
      "2025-01-18 10:21:15,158 - INFO - Frame 1150 - 49 aree di movimento\n",
      "2025-01-18 10:21:16,012 - INFO - Frame 1160 - 47 aree di movimento\n",
      "2025-01-18 10:21:16,896 - INFO - Frame 1170 - 48 aree di movimento\n",
      "2025-01-18 10:21:17,750 - INFO - Frame 1180 - 50 aree di movimento\n",
      "2025-01-18 10:21:18,615 - INFO - Frame 1190 - 51 aree di movimento\n",
      "2025-01-18 10:21:19,474 - INFO - Frame 1200 - 87 aree di movimento\n",
      "2025-01-18 10:21:20,322 - INFO - Frame 1210 - 46 aree di movimento\n",
      "2025-01-18 10:21:21,178 - INFO - Frame 1220 - 59 aree di movimento\n",
      "2025-01-18 10:21:22,035 - INFO - Frame 1230 - 41 aree di movimento\n",
      "2025-01-18 10:21:22,913 - INFO - Frame 1240 - 42 aree di movimento\n",
      "2025-01-18 10:21:23,809 - INFO - Frame 1250 - 42 aree di movimento\n",
      "2025-01-18 10:21:24,696 - INFO - Frame 1260 - 121 aree di movimento\n",
      "2025-01-18 10:21:25,579 - INFO - Frame 1270 - 53 aree di movimento\n",
      "2025-01-18 10:21:26,453 - INFO - Frame 1280 - 49 aree di movimento\n",
      "2025-01-18 10:21:27,008 - INFO - Fine del video.\n",
      "2025-01-18 10:21:27,442 - INFO - Video overlay salvato in: ../Dataset/output/flow_smoothing_output.mp4\n",
      "2025-01-18 10:21:27,443 - INFO - Video maschera salvato in: ../Dataset/output/movement_mask.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "def setup_logging(output_dir):\n",
    "    log_file = os.path.join(output_dir, \"motion_smoothing.log\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),  # Log su file\n",
    "            logging.StreamHandler()         # Log su console\n",
    "        ]\n",
    "    )\n",
    "    logging.info(\"Logging configurato. Log salvati in: %s\", log_file)\n",
    "\n",
    "def add_transparent_overlay(frame, boxes, color=(0, 0, 255), alpha=0.3):\n",
    "    \"\"\"\n",
    "    Disegna rettangoli rossi trasparenti sulle aree di movimento.\n",
    "    \"\"\"\n",
    "    overlay = frame.copy()\n",
    "    for (x, y, w, h) in boxes:\n",
    "        cv2.rectangle(overlay, (x, y), (x + w, y + h), color, -1)\n",
    "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "\n",
    "def temporal_smoothing_flow(\n",
    "    video_path, \n",
    "    output_dir, \n",
    "    flow_threshold=0.5,       # Soglia di magnitudo per considerare un pixel in movimento\n",
    "    alpha_fraction=0.2,       # Percentuale di frame su N in cui il pixel deve essere acceso\n",
    "    window_size=30,           # N: lunghezza finestra temporale\n",
    "    morph_kernel=3,           # Dimensione kernel morfologico ridotto\n",
    "    save_name=\"flow_smoothing_output.mp4\",\n",
    "    mask_save_name=\"movement_mask.mp4\",  # Nome del video maschera binaria\n",
    "    margin=10,                # Padding in pixel\n",
    "    scale_factor=0.5,         # Riduzione di scala per il calcolo dell'Optical Flow\n",
    "    skip_frames=0             # Numero di frame da saltare (0 = nessuno)\n",
    "):\n",
    "    \"\"\"\n",
    "    Rileva il movimento usando Farneback Optical Flow e produce:\n",
    "      - Un video con overlay (rettangoli rossi) = save_name\n",
    "      - Un video con maschera binaria (0/255) = mask_save_name\n",
    "    \"\"\"\n",
    "    logging.info(\"=== Inizio Optical Flow con Buffer Temporale ===\")\n",
    "    logging.info(f\"Video input: {video_path}\")\n",
    "    logging.info(f\"Finestra temporale: N={window_size}, soglia %={alpha_fraction}, scale_factor={scale_factor}\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        logging.error(\"Impossibile aprire il video.\")\n",
    "        return\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    logging.info(f\"FPS: {fps} | Dimensioni: {width}x{height}\")\n",
    "\n",
    "    # VideoWriter per video con overlay\n",
    "    fourcc_overlay = cv2.VideoWriter_fourcc(*'avc1')\n",
    "    output_path = os.path.join(output_dir, save_name)\n",
    "    out_overlay = cv2.VideoWriter(output_path, fourcc_overlay, fps, (width, height))\n",
    "\n",
    "    # VideoWriter per la maschera binaria (isColor=False)\n",
    "    fourcc_mask = cv2.VideoWriter_fourcc(*'avc1')\n",
    "    mask_output_path = os.path.join(output_dir, mask_save_name)\n",
    "    out_mask = cv2.VideoWriter(mask_output_path, fourcc_mask, fps, (width, height), isColor=False)\n",
    "\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        logging.error(\"Non riesco a leggere il primo frame.\")\n",
    "        return\n",
    "\n",
    "    # Converto il primo frame in scala di grigi e riduco per Optical Flow\n",
    "    prev_gray_full = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_gray = cv2.resize(prev_gray_full, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    # Deque per maschere negli ultimi N frame\n",
    "    mask_queue = deque(maxlen=window_size)\n",
    "    frame_count = 1\n",
    "\n",
    "    # Kernel morfologico\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_kernel, morph_kernel))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            logging.info(\"Fine del video.\")\n",
    "            break\n",
    "\n",
    "        # Se vuoi saltare frame per velocità\n",
    "        if skip_frames > 0 and frame_count % (skip_frames + 1) != 0:\n",
    "            gray_full = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.resize(gray_full, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "            prev_gray = gray.copy()\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        gray_full = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.resize(gray_full, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "        # Optical Flow\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            prev_gray, gray, None,\n",
    "            0.5,    # Scale\n",
    "            2,      # Levels\n",
    "            9,      # Winsize\n",
    "            2,      # Iterations\n",
    "            5,      # Poly_n\n",
    "            1.2,    # Poly_sigma\n",
    "            0       # Flags\n",
    "        )\n",
    "\n",
    "        # Magnitudo e Angolo\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1], angleInDegrees=False)\n",
    "        mask_current_resized = (mag > flow_threshold).astype(np.uint8) * 255\n",
    "        # Risali alla risoluzione originale\n",
    "        mask_current = cv2.resize(mask_current_resized, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Aggiungi la maschera alla coda\n",
    "        mask_queue.append(mask_current)\n",
    "\n",
    "        # Costruisci la maschera \"media\" con smoothing temporale\n",
    "        if frame_count <= window_size:\n",
    "            cumulative_mask = np.sum(np.array(mask_queue), axis=0)\n",
    "        else:\n",
    "            cumulative_mask = np.sum(np.array(mask_queue), axis=0)\n",
    "\n",
    "        mask_smoothed = (cumulative_mask >= (alpha_fraction * len(mask_queue) * 255)).astype(np.uint8) * 255\n",
    "\n",
    "        # Operazioni morfologiche\n",
    "        mask_smoothed = cv2.morphologyEx(mask_smoothed, cv2.MORPH_CLOSE, kernel)\n",
    "        mask_smoothed = cv2.morphologyEx(mask_smoothed, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Trova contorni e crea bounding box\n",
    "        contours, _ = cv2.findContours(mask_smoothed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        boxes = []\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            x_padded = max(0, x - margin)\n",
    "            y_padded = max(0, y - margin)\n",
    "            w_padded = min(w + 2*margin, width - x_padded)\n",
    "            h_padded = min(h + 2*margin, height - y_padded)\n",
    "\n",
    "            if w_padded > 5 and h_padded > 5:\n",
    "                boxes.append((x_padded, y_padded, w_padded, h_padded))\n",
    "\n",
    "        if frame_count % 10 == 0:\n",
    "            logging.info(f\"Frame {frame_count} - {len(boxes)} aree di movimento\")\n",
    "\n",
    "        # Disegno overlay\n",
    "        if boxes:\n",
    "            add_transparent_overlay(frame, boxes, (0, 0, 255), alpha=0.3)\n",
    "\n",
    "        # Scrivi il frame con overlay\n",
    "        out_overlay.write(frame)\n",
    "\n",
    "        # Crea la maschera binaria con rettangoli pieni\n",
    "        mask_rect = np.zeros((height, width), dtype=np.uint8)\n",
    "        for (x, y, w, h) in boxes:\n",
    "            cv2.rectangle(mask_rect, (x, y), (x + w, y + h), 255, -1)  # -1 riempie il rettangolo\n",
    "\n",
    "        # Scrivi la maschera binaria\n",
    "        out_mask.write(mask_rect)\n",
    "\n",
    "        # Opzionale: visualizza il frame con overlay\n",
    "        cv2.imshow(\"Temporal Smoothing Flow\", frame)\n",
    "\n",
    "        # Aggiorna\n",
    "        prev_gray = gray.copy()\n",
    "        frame_count += 1\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            logging.info(\"Interruzione manuale.\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out_overlay.release()\n",
    "    out_mask.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    logging.info(f\"Video overlay salvato in: {output_path}\")\n",
    "    logging.info(f\"Video maschera salvato in: {mask_output_path}\")\n",
    "\n",
    "def main():\n",
    "    video_path = \"../Dataset/input/test2.mp4\"\n",
    "    output_dir = \"../Dataset/output/\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    setup_logging(output_dir)\n",
    "    \n",
    "    temporal_smoothing_flow(\n",
    "        video_path=video_path,\n",
    "        output_dir=output_dir,\n",
    "        flow_threshold=0.5,\n",
    "        alpha_fraction=0.2,\n",
    "        window_size=9,\n",
    "        morph_kernel=3,\n",
    "        save_name=\"flow_smoothing_output.mp4\",\n",
    "        mask_save_name=\"movement_mask.mp4\",\n",
    "        margin=20,\n",
    "        scale_factor=0.5,\n",
    "        skip_frames=0\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-18 10:33:09,695 - INFO - Logging configurato. Log salvati in: ../Dataset/output/compression.log\n",
      "2025-01-18 10:33:09,719 - INFO - FPS: 60.05879882402352 | Dimensioni: 1920x1080\n",
      "2025-01-18 10:33:11.106 Python[14764:367833] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-18 10:33:11.106 Python[14764:367833] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "\n",
    "def setup_logging(output_dir):\n",
    "    log_file = os.path.join(output_dir, \"compression.log\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),  # Log su file\n",
    "            logging.StreamHandler()         # Log su console\n",
    "        ]\n",
    "    )\n",
    "    logging.info(\"Logging configurato. Log salvati in: %s\", log_file)\n",
    "\n",
    "def compress_frame_with_motion_mask(frame_bgr, mask, blockSize=8, QTY_static=None):\n",
    "    \"\"\"\n",
    "    Comprimi il frame in base alla maschera di movimento utilizzando DCT e quantizzazione.\n",
    "    \"\"\"\n",
    "    if QTY_static is None:\n",
    "        QTY_static = np.full((blockSize, blockSize), 50, dtype=np.float32)  # Quantizzazione aggressiva\n",
    "\n",
    "    # Converti il frame in YCrCb\n",
    "    H, W, _ = frame_bgr.shape\n",
    "    frame_ycrcb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    Y, Cr, Cb = cv2.split(frame_ycrcb)\n",
    "\n",
    "    Y_recon = np.zeros_like(Y, dtype=np.float32)\n",
    "\n",
    "    # Itera sui blocchi\n",
    "    for by in range(0, H, blockSize):\n",
    "        for bx in range(0, W, blockSize):\n",
    "            y_end = min(by + blockSize, H)\n",
    "            x_end = min(bx + blockSize, W)\n",
    "            blockY = Y[by:y_end, bx:x_end]\n",
    "            blockMask = mask[by:y_end, bx:x_end]\n",
    "\n",
    "            # Se il blocco è in movimento, non applicare la compressione\n",
    "            if np.mean(blockMask) > 0:  # Movimento presente\n",
    "                Y_recon[by:y_end, bx:x_end] = blockY\n",
    "            else:\n",
    "                # Comprimi il blocco con DCT e quantizzazione\n",
    "                paddedY = np.zeros((blockSize, blockSize), dtype=np.float32)\n",
    "                paddedY[:(y_end-by), :(x_end-bx)] = blockY\n",
    "\n",
    "                dct_block = cv2.dct(paddedY)  # Calcolo DCT\n",
    "                quant_block = np.round(dct_block / QTY_static)  # Quantizzazione\n",
    "                idct_block = cv2.idct(quant_block * QTY_static)  # Ricostruzione\n",
    "\n",
    "                Y_recon[by:y_end, bx:x_end] = idct_block[:(y_end-by), :(x_end-bx)]\n",
    "\n",
    "    # Ricostruisci il frame in YCrCb e converti in BGR\n",
    "    recon_frame_ycrcb = cv2.merge([Y_recon.astype(np.uint8), Cr, Cb])\n",
    "    recon_bgr = cv2.cvtColor(recon_frame_ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "    return recon_bgr\n",
    "\n",
    "def main_compress_with_motion(input_video, motionMask_video, output_video=\"COMPRESSION_test2.mp4\"):\n",
    "    \"\"\"\n",
    "    Comprimi le aree statiche basate sulla maschera binaria e utilizza H.264 per la compressione.\n",
    "    \"\"\"\n",
    "    cap_input = cv2.VideoCapture(input_video)\n",
    "    cap_mask = cv2.VideoCapture(motionMask_video)\n",
    "\n",
    "    if not cap_input.isOpened():\n",
    "        logging.error(f\"Impossibile aprire il video originale: {input_video}\")\n",
    "        return\n",
    "    if not cap_mask.isOpened():\n",
    "        logging.error(f\"Impossibile aprire il video maschera: {motionMask_video}\")\n",
    "        return\n",
    "\n",
    "    fps = cap_input.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap_input.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap_input.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    logging.info(f\"FPS: {fps} | Dimensioni: {width}x{height}\")\n",
    "\n",
    "    # VideoWriter per video compresso con codec H.264\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'avc1')  # H.264 codec\n",
    "    output_path = os.path.join(os.path.dirname(motionMask_video), output_video)\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Tabella di quantizzazione per aree statiche\n",
    "    QTY_static = np.full((8, 8), 200, dtype=np.int16)  # Compressione aggressiva\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret_in, frame_in = cap_input.read()\n",
    "        ret_mask, frame_mask = cap_mask.read()\n",
    "        if not ret_in or not ret_mask:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Comprimi il frame con maschera di movimento\n",
    "        compressed_frame = compress_frame_with_motion_mask(\n",
    "            frame_in, \n",
    "            frame_mask, \n",
    "            blockSize=8, \n",
    "            QTY_static=QTY_static\n",
    "        )\n",
    "\n",
    "        # Scrivi il frame compresso nel video di output\n",
    "        out.write(compressed_frame)\n",
    "\n",
    "        # Opzionale: visualizza il frame compresso\n",
    "        cv2.imshow(\"Compressed Frame\", compressed_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            logging.info(\"Interruzione manuale.\")\n",
    "            break\n",
    "\n",
    "    cap_input.release()\n",
    "    cap_mask.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    logging.info(f\"Elaborazione completata. Video compresso salvato in: {output_path}\")\n",
    "\n",
    "def main():\n",
    "    video_originale = \"../Dataset/input/test2.mp4\"\n",
    "    output_dir = \"../Dataset/output/\"\n",
    "    mask_video_path = os.path.join(output_dir, \"movement_mask.mp4\")  # Generato dal Blocco 1\n",
    "    video_compresso = \"COMPRESSION_test2.mp4\"\n",
    "    compressed_video_path = os.path.join(output_dir, video_compresso)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    setup_logging(output_dir)\n",
    "\n",
    "    main_compress_with_motion(\n",
    "        input_video=video_originale,\n",
    "        motionMask_video=mask_video_path,\n",
    "        output_video=video_compresso\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
